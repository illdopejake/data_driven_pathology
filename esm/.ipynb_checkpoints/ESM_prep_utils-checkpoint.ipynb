{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scripts to build\n",
    "* Extract values from Atlas\n",
    "* Convert to probabilities\n",
    "* Prepare inputs after masking\n",
    "* Generate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "import numpy as np\n",
    "import nibabel as ni\n",
    "from glob import glob\n",
    "from nilearn import image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Extract Values from Atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files_in = '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/'\n",
    "atlas = '/home/users/jvogel/Science/templates/atlases/Lund/hippocampus_labels_LUND_scif55_1p5.nii.gz'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It seems you passed a directory\n",
      "found 238 images!\n",
      "working on subject 0\n",
      "working on subject 1\n",
      "working on subject 2\n",
      "working on subject 3\n",
      "working on subject 4\n",
      "working on subject 5\n",
      "working on subject 6\n",
      "working on subject 7\n",
      "working on subject 8\n",
      "working on subject 9\n",
      "working on subject 10\n",
      "working on subject 11\n",
      "working on subject 12\n",
      "working on subject 13\n",
      "working on subject 14\n",
      "working on subject 15\n",
      "working on subject 16\n",
      "working on subject 17\n",
      "working on subject 18\n",
      "working on subject 19\n",
      "working on subject 20\n",
      "working on subject 21\n",
      "working on subject 22\n",
      "working on subject 23\n",
      "working on subject 24\n",
      "working on subject 25\n",
      "working on subject 26\n",
      "working on subject 27\n",
      "working on subject 28\n",
      "working on subject 29\n",
      "working on subject 30\n",
      "working on subject 31\n",
      "working on subject 32\n",
      "working on subject 33\n",
      "working on subject 34\n",
      "working on subject 35\n",
      "working on subject 36\n",
      "working on subject 37\n",
      "working on subject 38\n",
      "working on subject 39\n",
      "working on subject 40\n",
      "working on subject 41\n",
      "working on subject 42\n",
      "working on subject 43\n",
      "working on subject 44\n",
      "working on subject 45\n",
      "working on subject 46\n",
      "working on subject 47\n",
      "working on subject 48\n",
      "working on subject 49\n",
      "working on subject 50\n",
      "working on subject 51\n",
      "working on subject 52\n",
      "working on subject 53\n",
      "working on subject 54\n",
      "working on subject 55\n",
      "working on subject 56\n",
      "working on subject 57\n",
      "working on subject 58\n",
      "working on subject 59\n",
      "working on subject 60\n",
      "working on subject 61\n",
      "working on subject 62\n",
      "working on subject 63\n",
      "working on subject 64\n",
      "working on subject 65\n",
      "working on subject 66\n",
      "working on subject 67\n",
      "working on subject 68\n",
      "working on subject 69\n",
      "working on subject 70\n",
      "working on subject 71\n",
      "working on subject 72\n",
      "working on subject 73\n",
      "working on subject 74\n",
      "working on subject 75\n",
      "working on subject 76\n",
      "working on subject 77\n",
      "working on subject 78\n",
      "working on subject 79\n",
      "working on subject 80\n",
      "working on subject 81\n",
      "working on subject 82\n",
      "working on subject 83\n",
      "working on subject 84\n",
      "working on subject 85\n",
      "working on subject 86\n",
      "working on subject 87\n",
      "working on subject 88\n",
      "working on subject 89\n",
      "working on subject 90\n",
      "working on subject 91\n",
      "working on subject 92\n",
      "working on subject 93\n",
      "working on subject 94\n",
      "working on subject 95\n",
      "working on subject 96\n",
      "working on subject 97\n",
      "working on subject 98\n",
      "working on subject 99\n",
      "working on subject 100\n",
      "working on subject 101\n",
      "working on subject 102\n",
      "working on subject 103\n",
      "working on subject 104\n",
      "working on subject 105\n",
      "working on subject 106\n",
      "working on subject 107\n",
      "working on subject 108\n",
      "working on subject 109\n",
      "working on subject 110\n",
      "working on subject 111\n",
      "working on subject 112\n",
      "working on subject 113\n",
      "working on subject 114\n",
      "working on subject 115\n",
      "working on subject 116\n",
      "working on subject 117\n",
      "working on subject 118\n",
      "working on subject 119\n",
      "working on subject 120\n",
      "working on subject 121\n",
      "working on subject 122\n",
      "working on subject 123\n",
      "working on subject 124\n",
      "working on subject 125\n",
      "working on subject 126\n",
      "working on subject 127\n",
      "working on subject 128\n",
      "working on subject 129\n",
      "working on subject 130\n",
      "working on subject 131\n",
      "working on subject 132\n",
      "working on subject 133\n",
      "working on subject 134\n",
      "working on subject 135\n",
      "working on subject 136\n",
      "working on subject 137\n",
      "working on subject 138\n",
      "working on subject 139\n",
      "working on subject 140\n",
      "working on subject 141\n",
      "working on subject 142\n",
      "working on subject 143\n",
      "working on subject 144\n",
      "working on subject 145\n",
      "working on subject 146\n",
      "working on subject 147\n",
      "working on subject 148\n",
      "working on subject 149\n",
      "working on subject 150\n",
      "working on subject 151\n",
      "working on subject 152\n",
      "working on subject 153\n",
      "working on subject 154\n",
      "working on subject 155\n",
      "working on subject 156\n",
      "working on subject 157\n",
      "working on subject 158\n",
      "working on subject 159\n",
      "working on subject 160\n",
      "working on subject 161\n",
      "working on subject 162\n",
      "working on subject 163\n",
      "working on subject 164\n",
      "working on subject 165\n",
      "working on subject 166\n",
      "working on subject 167\n",
      "working on subject 168\n",
      "working on subject 169\n",
      "working on subject 170\n",
      "working on subject 171\n",
      "working on subject 172\n",
      "working on subject 173\n",
      "working on subject 174\n",
      "working on subject 175\n",
      "working on subject 176\n",
      "working on subject 177\n",
      "working on subject 178\n",
      "working on subject 179\n",
      "working on subject 180\n",
      "working on subject 181\n",
      "working on subject 182\n",
      "working on subject 183\n",
      "working on subject 184\n",
      "working on subject 185\n",
      "working on subject 186\n",
      "working on subject 187\n",
      "working on subject 188\n",
      "working on subject 189\n",
      "working on subject 190\n",
      "working on subject 191\n",
      "working on subject 192\n",
      "working on subject 193\n",
      "working on subject 194\n",
      "working on subject 195\n",
      "working on subject 196\n",
      "working on subject 197\n",
      "working on subject 198\n",
      "working on subject 199\n",
      "working on subject 200\n",
      "working on subject 201\n",
      "working on subject 202\n",
      "working on subject 203\n",
      "working on subject 204\n",
      "working on subject 205\n",
      "working on subject 206\n",
      "working on subject 207\n",
      "working on subject 208\n",
      "working on subject 209\n",
      "working on subject 210\n",
      "working on subject 211\n",
      "working on subject 212\n",
      "working on subject 213\n",
      "working on subject 214\n",
      "working on subject 215\n",
      "working on subject 216\n",
      "working on subject 217\n",
      "working on subject 218\n",
      "working on subject 219\n",
      "working on subject 220\n",
      "working on subject 221\n",
      "working on subject 222\n",
      "working on subject 223\n",
      "working on subject 224\n",
      "working on subject 225\n",
      "working on subject 226\n",
      "working on subject 227\n",
      "working on subject 228\n",
      "working on subject 229\n",
      "working on subject 230\n",
      "working on subject 231\n",
      "working on subject 232\n",
      "working on subject 233\n",
      "working on subject 234\n",
      "working on subject 235\n",
      "working on subject 236\n",
      "working on subject 237\n",
      "CPU times: user 1min 6s, sys: 4.1 s, total: 1min 10s\n",
      "Wall time: 2min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = Extract_Values_from_Atlas(files_in,atlas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It seems you passed a directory\n",
      "found 238 images!\n",
      "extracting values from atlas\n",
      "CPU times: user 9.42 s, sys: 13.2 s, total: 22.6 s\n",
      "Wall time: 1min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = Extract_Values_from_Atlas(files_in,atlas,blocking='all_at_once')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It seems you passed a directory\n",
      "found 238 images!\n",
      "working on batch 1 of 100 subjects\n",
      "processing 100 subjects\n",
      "working on batch 2 of 100 subjects\n",
      "processing 100 subjects\n",
      "working on final batch of subjects\n",
      "processing 38 subjects\n",
      "CPU times: user 9.38 s, sys: 6.43 s, total: 15.8 s\n",
      "Wall time: 57.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = Extract_Values_from_Atlas(files_in,atlas,blocking=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It seems you passed a directory\n",
      "found 238 images!\n",
      "working on batch 1 of 50 subjects\n",
      "processing 50 subjects\n",
      "working on batch 2 of 50 subjects\n",
      "processing 50 subjects\n",
      "working on batch 3 of 50 subjects\n",
      "processing 50 subjects\n",
      "working on batch 4 of 50 subjects\n",
      "processing 50 subjects\n",
      "working on final batch of subjects\n",
      "processing 38 subjects\n",
      "CPU times: user 9.52 s, sys: 4.38 s, total: 13.9 s\n",
      "Wall time: 46.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = Extract_Values_from_Atlas(files_in,atlas,blocking=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 10 subjects\n",
      "extracting values from atlas\n"
     ]
    }
   ],
   "source": [
    "files_in = glob('/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/*')[:10]\n",
    "atlas = '/home/users/jvogel/Science/templates/atlases/Lund/hippocampus_labels_LUND_scif55_1p5.nii.gz'\n",
    "labels = ['off_target','early_NFT']\n",
    "df = Extract_Values_from_Atlas(files_in,atlas,blocking='all_at_once', labels=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>off_target</th>\n",
       "      <th>early_NFT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.04061</td>\n",
       "      <td>-1.5576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.17887</td>\n",
       "      <td>-2.29193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.495905</td>\n",
       "      <td>-0.439328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.25555</td>\n",
       "      <td>-1.61055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.457695</td>\n",
       "      <td>-0.52681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.830459</td>\n",
       "      <td>-1.1219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.867813</td>\n",
       "      <td>-1.97659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.18883</td>\n",
       "      <td>-1.72155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.706084</td>\n",
       "      <td>-1.03505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1.16094</td>\n",
       "      <td>-2.35611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  off_target early_NFT\n",
       "0   -1.04061   -1.5576\n",
       "1   -1.17887  -2.29193\n",
       "2  -0.495905 -0.439328\n",
       "3   -1.25555  -1.61055\n",
       "4  -0.457695  -0.52681\n",
       "5  -0.830459   -1.1219\n",
       "6  -0.867813  -1.97659\n",
       "7   -1.18883  -1.72155\n",
       "8  -0.706084  -1.03505\n",
       "9   -1.16094  -2.35611"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 10 subjects\n",
      "working on subject sub_0\n",
      "working on subject sub_1\n",
      "working on subject sub_2\n",
      "working on subject sub_3\n",
      "working on subject sub_4\n",
      "working on subject sub_5\n",
      "working on subject sub_6\n",
      "working on subject sub_7\n",
      "working on subject sub_8\n",
      "working on subject sub_9\n"
     ]
    }
   ],
   "source": [
    "files_in = glob('/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/*')[:10]\n",
    "atlas = '/home/users/jvogel/Science/templates/atlases/Lund/hippocampus_labels_LUND_scif55_1p5.nii.gz'\n",
    "labels = ['off_target','early_NFT']\n",
    "sids = ['sub_%s'%x for x in range(10)]\n",
    "df2 = Extract_Values_from_Atlas(files_in,atlas,blocking='one_at_a_time', labels=labels, sids = sids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>off_target</th>\n",
       "      <th>early_NFT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sub_0</th>\n",
       "      <td>-1.04061</td>\n",
       "      <td>-1.5576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_1</th>\n",
       "      <td>-1.17887</td>\n",
       "      <td>-2.29193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_2</th>\n",
       "      <td>-0.495905</td>\n",
       "      <td>-0.439328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_3</th>\n",
       "      <td>-1.25555</td>\n",
       "      <td>-1.61055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_4</th>\n",
       "      <td>-0.457695</td>\n",
       "      <td>-0.52681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_5</th>\n",
       "      <td>-0.830459</td>\n",
       "      <td>-1.1219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_6</th>\n",
       "      <td>-0.867813</td>\n",
       "      <td>-1.97659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_7</th>\n",
       "      <td>-1.18883</td>\n",
       "      <td>-1.72155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_8</th>\n",
       "      <td>-0.706084</td>\n",
       "      <td>-1.03505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_9</th>\n",
       "      <td>-1.16094</td>\n",
       "      <td>-2.35611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      off_target early_NFT\n",
       "sub_0   -1.04061   -1.5576\n",
       "sub_1   -1.17887  -2.29193\n",
       "sub_2  -0.495905 -0.439328\n",
       "sub_3   -1.25555  -1.61055\n",
       "sub_4  -0.457695  -0.52681\n",
       "sub_5  -0.830459   -1.1219\n",
       "sub_6  -0.867813  -1.97659\n",
       "sub_7   -1.18883  -1.72155\n",
       "sub_8  -0.706084  -1.03505\n",
       "sub_9   -1.16094  -2.35611"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "import numpy as np\n",
    "import nibabel as ni\n",
    "from glob import glob\n",
    "\n",
    "def Extract_Values_from_Atlas(files_in, atlas, output = None, \n",
    "                              blocking = 'one_at_a_time', \n",
    "                              labels = [], sids = []):\n",
    "    '''\n",
    "    This function will extract mean values from a set of images for \n",
    "    each ROI from a given atlas. Returns a Subject x ROI pandas\n",
    "    DataFrame (and csv file if output argument is set to a path).\n",
    "    \n",
    "    Use blocking argument according to memory capacity of your\n",
    "    computer vis-a-vis memory requirements of loading all images.\n",
    "    \n",
    "    files_in: determines which images to extract values from. Input \n",
    "    can be any of the following:\n",
    "        -- a list of paths\n",
    "        -- a path to a directory containing ONLY files to extract from\n",
    "        -- a search string (with wild card) that would return all\n",
    "        desired images. For example, doing ls [files_in] in a terminal \n",
    "        would list all desired subjects\n",
    "        -- a 4D Nifti image\n",
    "        **NOTE** be aware of the order of file input, which relates to \n",
    "        other arguments\n",
    "        \n",
    "    atlas: Path to an atlas, or a Nifti image or np.ndarry of desired \n",
    "    atlas. Or, if doing native space analysis, instead, supply a list \n",
    "    of paths to atlases that match each subject. \n",
    "        NOTE: In this case, The order of this list should be the same\n",
    "        order as subjects in files_in\n",
    "        \n",
    "    output: if you wish the resulting ROI values to be written to file,\n",
    "    provide a FULL path. Otherwise, leave as None (matrix will be \n",
    "    returned)\n",
    "    \n",
    "    blocking: loading all images to memory at once may not be possible\n",
    "    depending on your computer. Acceptable arguments are:\n",
    "        -- 'one_at_a_time': will extract values from each image\n",
    "        independently. Recommended for memories with poor memory \n",
    "        capacity. Required for native space extraction.\n",
    "        -- 'all_at_once': loads all images into memory at once.\n",
    "        Provides a slight speed up for faster machines overe\n",
    "        one_at_a_time, but is probably not faster than batching (see\n",
    "        below). Only recommended for smaller datasets.\n",
    "        ** WARNING ** Not recommended on very large datasets. Will\n",
    "        crash computers with poor memory capacity.\n",
    "        -- any integer: determines the number of images to be read to\n",
    "        memory at once. Recommended for large datasets. \n",
    "    \n",
    "    labels: a list of string labels that represent the names of the\n",
    "    ROIs from atlas. \n",
    "        NOTE: ROIs are read consecutively from lowest to highest, and\n",
    "        labels *must* match that order\n",
    "    Default argument [] will use \"ROI_x\" for each ROI, where X\n",
    "    corresponds to the actual ROI integer lael\n",
    "    \n",
    "    sids: a list of subject IDs in the same order as files_in. Default \n",
    "    argument [] will list subjects with consecutive integers.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    if type(blocking) == str and blocking not in ['all_at_once','one_at_a_time']:\n",
    "        raise IOError('blocking only accepts integers or argumennts of \"all_at_once\" or \"one_at_a_time\"')\n",
    "    \n",
    "    if type(atlas) == list: \n",
    "        if blocking != 'one_at_a_time':\n",
    "            print('WARNING: you have passed a list of atlases but blocking is not set to one_at_a_time')\n",
    "            print('Lists of atlases are for native space situations where each subject has their own atlas')\n",
    "            print('If you want to test multiple atlases, run the script multiple times with different atlases')\n",
    "            raise IOError('you have passed a list of atlases but blocking is not set to one_at_a_time')\n",
    "    \n",
    "    if type(atlas) != list:\n",
    "        if type(atlas) == str:\n",
    "            try:\n",
    "                atl = ni.load(atlas).get_data()\n",
    "            except:\n",
    "                raise IOError('could not find an atlas at the specified location: %s'%atlas)\n",
    "        elif type(atlas) == ni.nifti1.Nifti1Image:\n",
    "            atl = atlas.get_data()\n",
    "        elif type(atlas) == np.ndarray:\n",
    "            atl = atlas\n",
    "        else:\n",
    "            print('could not recognize atlas filetype. Please provide a path, a NiftiImage object, or an numpy ndarray')\n",
    "            raise IOError('atlas type not recognized')\n",
    "        \n",
    "        if blocking == 'all_at_once':\n",
    "            i4d = load_data(files_in, return_images=True)\n",
    "            if i4d.shape[:-1] != atl.shape:\n",
    "                raise IOError('image dimensions do not match atlas dimensions')\n",
    "            if len(sids) == 0:\n",
    "                sids = range(i4d.shape[-1])\n",
    "            print('extracting values from atlas')\n",
    "            roi_vals = generate_matrix_from_atlas(i4d.get_data(), atl, labels, sids)\n",
    "        else:\n",
    "            image_paths = load_data(files_in, return_images = False)\n",
    "            if blocking == 'one_at_a_time':\n",
    "                catch = []\n",
    "                for i,image_path in enumerate(image_paths):\n",
    "                    if len(sids) > 0: \n",
    "                        sid = [sids[i]]\n",
    "                    else:\n",
    "                        sid = [i]\n",
    "                    print('working on subject %s'%sid[0])\n",
    "                    img = ni.load(image_path).get_data()\n",
    "                    try:\n",
    "                        assert img.shape == atl.shape, 'fail'\n",
    "                    except:\n",
    "                        print('dimensions for subject %s (%s) image did not match atlas dimensions (%s)'%(sid,\n",
    "                                                                                 img.shape,\n",
    "                                                                                 atl.shape))\n",
    "                        print('skipping subject %s'%sid[0])\n",
    "                        continue\n",
    "                    f_mat = generate_matrix_from_atlas(img, atl, labels, sid)\n",
    "                    catch.append(f_mat)\n",
    "                roi_vals = pandas.concat(catch)\n",
    "            elif type(blocking) == int:\n",
    "                block_size = blocking\n",
    "                if len(image_paths)%block_size == 0:\n",
    "                    blocks = int(len(image_paths)/block_size)\n",
    "                    remainder = False\n",
    "                else:\n",
    "                    blocks = int((len(image_paths)/blocking) + 1)\n",
    "                    remainder = True\n",
    "                catch = []\n",
    "                count = 0\n",
    "                for block in range(blocks):\n",
    "                    if block == (blocks - 1) and remainder:\n",
    "                        print('working on final batch of subjects')\n",
    "                        sub_block = image_paths[count:]\n",
    "                    else:\n",
    "                        print('working on batch %s of %s subjects'%((block+1),block_size))\n",
    "                        sub_block = image_paths[count:(count+block_size)]\n",
    "                    i4d = load_data(sub_block, return_images = True)\n",
    "                    if i4d.shape[:-1] != atl.shape:\n",
    "                        raise IOError('image dimensions (%s) do not match atlas dimensions (%)'%(atl.shape,\n",
    "                                                                                                i4d.shape[:-1]\n",
    "                                                                                                ))\n",
    "                    if len(sids) == 0:\n",
    "                        sids_in = range(i4d.shape[-1])\n",
    "                    elif block == (blocks - 1) and remainder:\n",
    "                        sids_in = sids[count:]\n",
    "                    else:\n",
    "                        sids_in = sids[count:(count+block_size)]\n",
    "                    f_mat = generate_matrix_from_atlas(i4d.get_data(), atl, labels, sids_in)\n",
    "                    catch.append(f_mat)\n",
    "                    count += block_size\n",
    "                roi_vals = pandas.concat(catch)\n",
    "    else:\n",
    "        image_paths = load_data(files_in, return_images = False)\n",
    "        if len(atlas) != len(image_paths):\n",
    "            raise IOError('number of images (%s) does not match number of atlases (%s)'%(len(image_paths),\n",
    "                                                                                      len(atlas)))\n",
    "        catch = []\n",
    "        for i,image_path in enumerate(image_paths):\n",
    "            if len(sids) > 0: \n",
    "                sid = [i]\n",
    "            else:\n",
    "                sid = [sids[i]]\n",
    "            print('working on subject'%sid)\n",
    "            img = ni.load(image_path).get_data()\n",
    "            atl = ni.load(atlas[i]).get_data()\n",
    "            try:\n",
    "                assert img.shape == atl.shape, 'fail'\n",
    "            except:\n",
    "                print('dimensions for subject %s (%s) image did not match atlas dimensions (%s)'%(sid,\n",
    "                                                                                                 img.shape,\n",
    "                                                                                                 atl.shape\n",
    "                                                                                                 ))\n",
    "                print('skipping subject %s'%sid)\n",
    "                continue\n",
    "            f_mat = generate_matrix_from_atlas(img, atl, labels, sid)\n",
    "            catch.append(f_mat)\n",
    "        roi_vals = pandas.concat(catch)    \n",
    "\n",
    "    if output:\n",
    "        roi_vals.to_csv(output)\n",
    "    return roi_vals\n",
    "    \n",
    "def generate_matrix_from_atlas(files_in, atl, labels, sids):\n",
    "    \n",
    "    if len(files_in.shape) == 3:\n",
    "        x,y,z = files_in.shape\n",
    "        files_in = files_in.reshape(x,y,z,1)\n",
    "    atl = atl.astype(int)\n",
    "    if max(np.unique(atl)) != (len(np.unique(atl)) -1):\n",
    "        new_atl = np.zeros_like(atl)\n",
    "        atl_map = dict(zip(np.unique(atl),\n",
    "                           range(len(np.unique(atl)))\n",
    "                          ))\n",
    "        for u in np.unique(atl):\n",
    "            new_atl[atl == u] = atl_map[u]\n",
    "        atl = new_atl\n",
    "    if len(labels) > 0:\n",
    "        cols = labels\n",
    "    else:\n",
    "        cols = ['roi_%s'%x for x in np.unique(atl) if x != 0]\n",
    "    f_mat = pandas.DataFrame(index = sids,\n",
    "                             columns = cols)\n",
    "    tot = np.bincount(atl.flat)\n",
    "    for sub in range(files_in.shape[-1]):\n",
    "        mtx = files_in[:,:,:,sub]\n",
    "        sums = np.bincount(atl.flat, weights = mtx.flat)\n",
    "        rois = (sums/tot)[1:]\n",
    "        f_mat.loc[f_mat.index[sub]] = rois\n",
    "    \n",
    "    return f_mat\n",
    "    \n",
    "\n",
    "def load_data(files_in, return_images):\n",
    "    \n",
    "    fail = False\n",
    "    \n",
    "    if type(files_in) == str:\n",
    "        if os.path.isdir(files_in):\n",
    "            print('It seems you passed a directory')\n",
    "            search = os.path.join(files_in,'*')\n",
    "            flz = glob(search)\n",
    "            num_f = len(flz)\n",
    "            if num_f == 0:\n",
    "                raise IOError('specified directory did not contain any files')\n",
    "            else:\n",
    "                print('found %s images!'%num_f)\n",
    "            if return_images:\n",
    "                i4d = ni.concat_images(flz)\n",
    "        elif '*' in files_in:\n",
    "            print('It seems you passed a search string')\n",
    "            flz = glob(files_in)\n",
    "            num_f = len(flz)\n",
    "            if num_f == 0:\n",
    "                raise IOError('specified search string did not result in any files')\n",
    "            else:\n",
    "                print('found %s images'%num_f)\n",
    "            if return_images:\n",
    "                i4d = ni.concat_images(flz)\n",
    "        else:\n",
    "            fail = True\n",
    "    elif type(files_in) == list:\n",
    "        flz = files_in\n",
    "        print('processing %s subjects'%len(files_in))\n",
    "        if return_images:\n",
    "            i4d = ni.concat_images(files_in)\n",
    "    elif type(files_in) == ni.nifti1.Nifti1Image:\n",
    "        print('processing %s subjects'%files_in.shape[-1])\n",
    "        i4d = files_in\n",
    "    else:\n",
    "        fail = True\n",
    "        \n",
    "    if fail:\n",
    "        print('files_in not recognized.', \n",
    "                    'Please enter a search string, valid directory, list of paths, or a Nifti object')\n",
    "        raise ValueError('I do not recognize the files_in input.')\n",
    "    \n",
    "    if return_images:\n",
    "        return i4d\n",
    "    else:\n",
    "        return flz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It seems you passed a directory\n",
      "found 238 images!\n"
     ]
    }
   ],
   "source": [
    "files_in = '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/'\n",
    "atlas = '/home/users/jvogel/Science/templates/atlases/Lund/hippocampus_labels_LUND_scif55_1p5.nii.gz'\n",
    "output = None\n",
    "blocking = 'one_at_a_time'\n",
    "labels = []\n",
    "sids = []\n",
    "\n",
    "\n",
    "if type(blocking) == str and blocking not in ['all_at_once','one_at_a_time']:\n",
    "    raise IOError('blocking only accepts integers or argumennts of \"all_at_once\" or \"one_at_a_time\"')\n",
    "\n",
    "if type(atlas) == list: \n",
    "    if blocking != 'one_at_a_time':\n",
    "        print('WARNING: you have passed a list of atlases but blocking is not set to one_at_a_time')\n",
    "        print('Lists of atlases are for native space situations where each subject has their own atlas')\n",
    "        print('If you want to test multiple atlases, run the script multiple times with different atlases')\n",
    "        raise IOError('you have passed a list of atlases but blocking is not set to one_at_a_time')\n",
    "\n",
    "if type(atlas) != list:\n",
    "    if type(atlas) == str:\n",
    "        try:\n",
    "            atl = ni.load(atlas).get_data()\n",
    "        except:\n",
    "            raise IOError('could not find an atlas at the specified location: %s'%atlas)\n",
    "    elif type(atlas) == ni.nifti1.Nifti1Image:\n",
    "        atl = atlas.get_data()\n",
    "    elif type(atlas) == np.ndarray:\n",
    "        atl = atlas\n",
    "    else:\n",
    "        print('could not recognize atlas filetype. Please provide a path, a NiftiImage object, or an numpy ndarray')\n",
    "        raise IOError('atlas type not recognized')\n",
    "\n",
    "    if blocking == 'all_at_once':\n",
    "        i4d = load_data(files_in, return_images=True)\n",
    "        if i4d.shape[:-1] != atl.shape:\n",
    "            raise IOError('image dimensions do not match atlas dimensions')\n",
    "        if len(sids) == 0:\n",
    "            sids = range(i4d.shape[-1])\n",
    "        roi_vals = generate_matrix_from_atlas(i4d, atl, labels, sids)\n",
    "    else:\n",
    "        image_paths = load_data(files_in, return_images = False)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on subject 0\n"
     ]
    }
   ],
   "source": [
    "catch = []\n",
    "i = 0\n",
    "image_path = image_paths[i]\n",
    "\n",
    "if len(sids) > 0: \n",
    "    sid = [sids[i]]\n",
    "else:\n",
    "    sid = [i]\n",
    "print('working on subject %s'%sid[0])\n",
    "img = ni.load(image_path).get_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on batch 1 of 100 subjects\n",
      "processing 100 subjects\n"
     ]
    }
   ],
   "source": [
    "blocking = 100\n",
    "block_size = blocking\n",
    "if len(image_paths)%block_size == 0:\n",
    "    blocks = len(image_paths)/block_size\n",
    "    remainder = False\n",
    "else:\n",
    "    blocks = int((len(image_paths)/blocking) + 1)\n",
    "    remainder = True\n",
    "catch = []\n",
    "count = 0\n",
    "for block in range(blocks):\n",
    "    if block == (blocks - 1) and remainder:\n",
    "        print('working on final batch of subjects')\n",
    "        sub_block = image_paths[count:]\n",
    "    else:\n",
    "        print('working on batch %s of %s subjects'%((block+1),block_size))\n",
    "        sub_block = image_paths[count:(count+block_size)]\n",
    "    i4d = load_data(sub_block, return_images = True)\n",
    "    if i4d.shape[:-1] != atl.shape:\n",
    "        raise IOError('image dimensions (%s) do not match atlas dimensions (%)'%(atl.shape,\n",
    "                                                                                i4d.shape[:-1]\n",
    "                                                                                ))\n",
    "    if len(sids) == 0:\n",
    "        sids_in = range(i4d.shape[-1])\n",
    "    elif block == (blocks - 1) and remainder:\n",
    "        sids_in = sids[count:]\n",
    "    else:\n",
    "        sids_in = sids[count:(count+block_size)]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 100)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sids_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(new_atl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 1, 3: 2}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atl_map = dict(zip(np.unique(atl),\n",
    "                       range(len(np.unique(atl)))\n",
    "                      ))\n",
    "atl_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_atl[atl == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/002_S_0413_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/041_S_5078_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/016_S_4952_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/002_S_5178_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/135_S_5269_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/041_S_4874_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/002_S_1261_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/019_S_4548_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/130_S_4417_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/127_S_4604_v2_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/027_S_5109_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/041_S_4876_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/027_S_2336_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/022_S_2263_v2_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/137_S_0668_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/007_S_4637_v2_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/041_S_4513_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/041_S_4143_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/135_S_4281_v2_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/TEST_019_S_5242_v1_prediction_image.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/127_S_4604_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/024_S_4169_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/137_S_4587_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/135_S_5113_v2_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/141_S_1378_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/002_S_4262_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/021_S_4254_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/018_S_4400_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/053_S_4813_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/135_S_4309_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/067_S_2301_v2_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/067_S_2304_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/137_S_0722_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/019_S_5242_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/137_S_0668_v2_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/027_S_2245_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/027_S_4869_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/023_S_1190_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/135_S_5273_v2_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/027_S_2219_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/002_S_5230_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/127_S_5200_v2_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/135_S_4446_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/019_S_4367_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/067_S_4782_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/130_S_2373_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/094_S_4649_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/135_S_4489_v2_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/135_S_4723_v2_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/127_S_4197_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/135_S_4489_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/127_S_2234_v2_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/135_S_4356_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/094_S_4630_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/021_S_0626_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/002_S_1155_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/127_S_4148_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/003_S_1122_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/002_S_4229_v2_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/018_S_4889_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/021_S_4659_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/135_S_5273_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/099_S_4076_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/128_S_4842_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/018_S_4399_v2_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/094_S_4234_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/027_S_5083_v2_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/023_S_1190_v2_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/114_S_0416_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/019_S_4835_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/067_S_4767_v2_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/127_S_4765_v2_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/137_S_4520_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/067_S_4767_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/009_S_5176_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/011_S_4893_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/027_S_4926_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/021_S_4744_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/041_S_4427_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/022_S_0096_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/014_S_4401_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/135_S_4598_v2_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/067_S_2301_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/041_S_4427_v2_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/141_S_4160_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/018_S_0142_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/024_S_4674_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/128_S_4742_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/024_S_2239_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/019_S_4293_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/137_S_1414_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/135_S_5269_v2_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/941_S_4292_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/021_S_5194_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/127_S_4198_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/130_S_0969_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/018_S_4809_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/037_S_0467_v2_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/068_S_4424_v1_smooth_AV1451_wscored_SUVR.nii',\n",
       " '/home/users/jvogel/Science/ADNI_tau/template_space/tau_images/smoothed_wscored_scans/002_S_4654_v1_smooth_AV1451_wscored_SUVR.nii']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_paths[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
